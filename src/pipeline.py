# -*- coding: utf-8 -*-
"""pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ka-AWG7aCySYhwBVL5Vhcruspm3tcy_u
"""

import pandas as pd
import joblib
import config
from sklearn.ensemble import RandomForestRegressor
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import LabelEncoder

def run_training_pipeline():
    """
    Orchestrates the entire Model Training process:
    1. Load Data
    2. Clean & Preprocess
    3. Feature Engineering
    4. Feature Selection
    5. Training
    6. Saving Artifacts
    """
    print("üöÄ Starting Training Pipeline...")

    # --- 1. Load Data ---
    try:
        df = pd.read_csv(config.DATA_PATH)
        print(f"   Data Loaded. Shape: {df.shape}")
    except FileNotFoundError:
        print(f"‚ùå Critical Error: Data file not found at {config.DATA_PATH}")
        return

    # --- 2. Clean & Preprocess ---
    target = '% Death Cardiovascular'

    # Drop rows where we don't know the answer (Target is NaN)
    df_train = df.dropna(subset=[target]).copy()

    # Filter out Aggregates (using the list from config)
    df_train = df_train[~df_train['Country'].isin(config.AGGREGATE_COUNTRIES)].copy()

    # Encode Gender (0=Both, 1=Female, 2=Male)
    # Note: We hardcode this mapping to ensure consistency with the App
    gender_map = {'Both sexes': 0, 'Female': 1, 'Male': 2}
    # Fallback: If data uses different strings, use LabelEncoder, but mapping is safer for production
    if df_train['Gender'].dtype == 'object':
        df_train['Gender'] = df_train['Gender'].map(gender_map)
        # Drop rows where gender mapping failed (if any)
        df_train = df_train.dropna(subset=['Gender'])

    # --- 3. Feature Engineering ---
    # We must replicate the math from Notebook 3 / inference.py exactly!
    print("   Applying Feature Engineering...")

    # A. Risk Combo
    df_train['Risk_Metabolic_Combo'] = df_train['Diet Composition Sugar'] * df_train['Diet Calories Fat']

    # B. Veg/Grain Ratio (Add +1 to avoid zero division)
    df_train['Ratio_Veg_to_Grain'] = df_train['Vegetable Consumption'] / (
        df_train['Cereal Consumption Wheat'] + df_train['Cereal Consumption Rice'] + 1
    )

    # --- 4. Feature Selection ---
    # Select ONLY the 12 features defined in config.MODEL_FEATURES
    try:
        X = df_train[config.MODEL_FEATURES]
        y = df_train[target]
        print(f"   Selected {len(config.MODEL_FEATURES)} Features.")
    except KeyError as e:
        print(f"‚ùå Error: Missing columns in dataset. {e}")
        return

    # --- 5. Train Model ---
    print("   Training Random Forest Model...")
    # Using the best params found in optimization
    pipeline = Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('rf', RandomForestRegressor(n_estimators=200, max_depth=None, random_state=42))
    ])

    pipeline.fit(X, y)

    # --- 6. Save Artifacts ---
    joblib.dump(pipeline, config.MODEL_PATH)
    joblib.dump(config.MODEL_FEATURES, config.FEATURE_PATH)

    print("‚úÖ Pipeline Finished Successfully.")
    print(f"   Model saved to: {config.MODEL_PATH}")
    print(f"   Features saved to: {config.FEATURE_PATH}")

if __name__ == "__main__":
    run_training_pipeline()